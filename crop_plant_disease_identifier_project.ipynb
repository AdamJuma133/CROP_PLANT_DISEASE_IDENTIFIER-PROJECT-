[![Open In Colab](/colab.research.google.com/assets/colab-badge.svg)](/colab.research.google.com/github/AdamJuma133/CROP_PLANT_DISEASE_IDENTIFIER-PROJECT-/blob/main/crop_plant_disease_identifier_project.ipynd)

# Crop Plant Disease Identifier Project

## Table of Contents
1. [Exploration](#exploration)
    - [Ideation](#ideation)
    - [Data Sourcing](#data-sourcing)
    - [Data Preparation](#data-preparation)
2. [Model Selection](#model-selection)
    - [Provide Pre-trained Models](#provide-pre-trained-models)
    - [Compare Performance](#compare-performance)
3. [Model Training](#model-training)
    - [Data Split](#data-split)
    - [Transfer Learning](#transfer-learning)
    - [Evaluation](#evaluation)
4. [Demo](#demo)
    - [Results](#results)
    - [Interactive Interface](#interactive-interface)
    - [Presentation](#presentation)

## Exploration

### Ideation

The goal of this project is to create a multi-class crop-plant-disease-identifier using a Convolutional Neural Network (CNN) model. The model will be trained to identify various diseases affecting different crop plants based on images. This will help farmers and agricultural professionals quickly diagnose plant diseases and take appropriate measures.

#### Key Objectives:
- Identify different types of diseases affecting crop plants.
- Use a CNN model for image classification.
- Utilize transfer learning with pre-trained models to improve accuracy and reduce training time.
- Evaluate the performance of different models and select the best one.
- Provide an interactive interface for users to upload images and get disease predictions.

### Data Sourcing

The dataset will be sourced from Google Drive. The dataset should contain images of crop plants affected by various diseases, categorized into different folders. Each folder should represent a specific disease and contain images related to that disease.

#### Steps to Source Data:
1. Collect a dataset of crop plant images with various diseases.
2. Organize the dataset into folders where each folder represents a specific disease.
3. Upload the dataset to Google Drive.

### Data Preparation

Data preparation involves loading the images from Google Drive, applying data augmentation techniques, and preparing the data for training.

#### Steps for Data Preparation:
1. **Mount Google Drive**: Use Google Colab to mount Google Drive and access the dataset.
2. **Define Data Paths**: Specify the paths to the training, validation, and test datasets.
3. **Data Augmentation**: Apply data augmentation techniques to increase the diversity of the training data and improve the model's generalization.
4. **Data Generators**: Create data generators to load and preprocess the images for training, validation, and testing.

```python
# Import necessary libraries
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Define paths for dataset
train_dir = '/content/drive/MyDrive/dataset/train'
val_dir = '/content/drive/MyDrive/dataset/val'
test_dir = '/content/drive/MyDrive/dataset/test'

# Data Augmentation and Preparation
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

val_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='categorical'
)

val_generator = val_datagen.flow_from_directory(
    val_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='categorical'
)

test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='categorical'
)
```

## Model Selection

### Provide Pre-trained Models

In this section, we will use pre-trained models to leverage transfer learning. Transfer learning allows us to use pre-existing knowledge from models trained on large datasets (such as ImageNet) and apply it to our specific problem. We will use two popular pre-trained models: VGG16 and ResNet50.

#### Steps for Using Pre-trained Models:
1. Import the pre-trained models from `tensorflow.keras.applications`.
2. Modify the models to fit our specific classification task.
3. Compile the models.

```python
# Import necessary libraries
from tensorflow.keras.applications import VGG16, ResNet50
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Dropout
from tensorflow.keras.optimizers import Adam

# Function to create a model using a pre-trained base
def create_model(base_model):
    model = Sequential([
        base_model,
        Flatten(),
        Dense(512, activation='relu'),
        Dropout(0.5),
        Dense(train_generator.num_classes, activation='softmax')
    ])
    return model

# Load pre-trained models
vgg_base = VGG16(input_shape=(150, 150, 3), include_top=False, weights='imagenet')
resnet_base = ResNet50(input_shape=(150, 150, 3), include_top=False, weights='imagenet')

# Create models using the pre-trained bases
vgg_model = create_model(vgg_base)
resnet_model = create_model(resnet_base)

# Compile the models
vgg_model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])
resnet_model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])
```

### Compare Performance

Next, we will train and evaluate both models to compare their performance. We will train the models on our training dataset, validate them on the validation dataset, and then evaluate their performance on the test dataset.

#### Steps for Comparing Performance:
1. Train both models using the training and validation data.
2. Plot the training and validation accuracy and loss for both models.
3. Evaluate the models on the test data.

```python
# Train the VGG16 model
history_vgg = vgg_model.fit(
    train_generator,
    epochs=10,
    validation_data=val_generator
)

# Train the ResNet50 model
history_resnet = resnet_model.fit(
    train_generator,
    epochs=10,
    validation_data=val_generator
)

# Function to plot the performance of a model
def plot_performance(history, title):
    acc = history.history['accuracy']
    val_acc = history.history['val_accuracy']
    loss = history.history['loss']
    val_loss = history.history['val_loss']
    epochs = range(len(acc))

    plt.figure(figsize=(12, 4))
    plt.subplot(1, 2, 1)
    plt.plot(epochs, acc, 'r', label='Training accuracy')
    plt.plot(epochs, val_acc, 'b', label='Validation accuracy')
    plt.title(f'{title} - Training and validation accuracy')
    plt.legend()

    plt.subplot(1, 2, 2)
    plt.plot(epochs, loss, 'r', label='Training loss')
    plt.plot(epochs, val_loss, 'b', label='Validation loss')
    plt.title(f'{title} - Training and validation loss')
    plt.legend()

    plt.show()

# Plot the performance of both models
plot_performance(history_vgg, 'VGG16')
plot_performance(history_resnet, 'ResNet50')

# Evaluate the models on the test data
vgg_test_loss, vgg_test_acc = vgg_model.evaluate(test_generator)
resnet_test_loss, resnet_test_acc = resnet_model.evaluate(test_generator)

print(f"VGG16 Test Accuracy: {vgg_test_acc}")
print(f"ResNet50 Test Accuracy: {resnet_test_acc}")
```

## Model Training

### Data Split

In this section, we will split our data into training, validation, and test sets. This ensures that our model is trained, validated, and tested on separate datasets to avoid overfitting and ensure generalization.

### Transfer Learning

We will use transfer learning to leverage pre-trained models (VGG16 and ResNet50) and fine-tune them for our specific classification task. Transfer learning allows us to use the knowledge from pre-trained models, reducing training time and improving accuracy.

#### Steps for Transfer Learning:
1. **Load Pre-trained Models**: Load the pre-trained VGG16 and ResNet50 models.
2. **Modify the Models**: Add custom layers to the pre-trained models to fit our classification task.
3. **Compile the Models**: Compile the modified models with appropriate loss functions and optimizers.
4. **Train the Models**: Train the models on our training dataset and validate them on the validation dataset.

```python
# Import necessary libraries
from tensorflow.keras.applications import VGG16, ResNet50
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Dropout
from tensorflow.keras.optimizers import Adam

# Function to create a model using a pre-trained base
def create_model(base_model):
    model = Sequential([
        base_model,
        Flatten(),
        Dense(512, activation='relu'),
        Dropout(0.5),
        Dense(train_generator.num_classes, activation='softmax')
    ])
    return model

# Load pre-trained models
vgg_base = VGG16(input_shape=(150, 150, 3), include_top=False, weights='imagenet')
resnet_base = ResNet50(input_shape=(150, 150, 3), include_top=False, weights='imagenet')

# Create models using the pre-trained bases
vgg_model = create_model(vgg_base)
resnet_model = create_model(resnet_base)

# Compile the models
vgg_model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])
resnet_model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])

# Train the VGG16 model
history_vgg = vgg_model.fit(
    train_generator,
    epochs=10,
    validation_data=val_generator
)

# Train the ResNet50 model
history_resnet = resnet_model.fit(
    train_generator,
    epochs=10,
    validation_data=val_generator
)
```

### Evaluation

After training the models, we will evaluate their performance using the test dataset. We will also plot the training and validation accuracy and loss for both models to visualize their performance.

#### Steps for Evaluation:
1. **Evaluate the Models**: Evaluate the trained models on the test dataset.
2. **Plot Performance**: Plot the training and validation accuracy and loss for both models.
3. **Print Test Accuracy**: Print the test accuracy for both models.

```python
# Function to plot the performance of a model
def plot_performance(history, title):
    acc = history.history['accuracy']
    val_acc = history.history['val_accuracy']
    loss = history.history['loss']
    val_loss = history.history['val_loss']
    epochs = range(len(acc))

    plt.figure(figsize=(12, 4))
    plt.subplot(1, 2, 1)
    plt.plot(epochs, acc, 'r', label='Training accuracy')
    plt.plot(epochs, val_acc, 'b', label='Validation accuracy')
    plt.title(f'{title} - Training and validation accuracy')
    plt.legend()

    plt.subplot(1, 2, 2)
    plt.plot(epochs, loss, 'r', label='Training loss')
    plt.plot(epochs, val_loss, 'b', label='Validation loss')
    plt.title(f'{title} - Training and validation loss')
    plt.legend()

    plt.show()

# Plot the performance of both models
plot_performance(history_vgg, 'VGG16')
plot_performance(history_resnet, 'ResNet50')

# Evaluate the models on the test data
vgg_test_loss, vgg_test_acc = vgg_model.evaluate(test_generator)
resnet_test_loss, resnet_test_acc = resnet_model.evaluate(test_generator)

print(f"VGG16 Test Accuracy: {vgg_test_acc}")
print(f"ResNet50 Test Accuracy: {resnet_test_acc}")
```

## Demo

### Results

In this section, we will present the results of our trained models. This includes visualizing the performance metrics and showing some example predictions.

#### Steps for Presenting Results:
1. **Visualize Model Performance**: Use plots to show the training and validation accuracy and loss for the models.
2. **Show Example Predictions**: Display some example images from the test set along with their predicted and actual labels.

```python
import matplotlib.pyplot as plt
import numpy as np
import os
import tensorflow as tf

# Function to plot the performance of a model
def plot_performance(history, title):
    acc = history.history['accuracy']
    val_acc = history.history['val_accuracy']
    loss = history.history['loss']
    val_loss = history.history['val_loss']
    epochs = range(len(acc))

    plt.figure(figsize=(12, 4))
    plt.subplot(1, 2, 1)
    plt.plot(epochs, acc, 'r', label='Training accuracy')
    plt.plot(epochs, val_acc, 'b', label='Validation accuracy')
    plt.title(f'{title} - Training and validation accuracy')
    plt.legend()

    plt.subplot(1, 2, 2)
    plt.plot(epochs, loss, 'r', label='Training loss')
    plt.plot(epochs, val_loss, 'b', label='Validation loss')
    plt.title(f'{title} - Training and validation loss')
    plt.legend()

    plt.show()

# Plot the performance of both models
plot_performance(history_vgg, 'VGG16')
plot_performance(history_resnet, 'ResNet50')

# Function to predict and display results for a single image
def predict_image(model, img_path):
    img = tf.keras.preprocessing.image.load_img(img_path, target_size=(150, 150))
    img_array = tf.keras.preprocessing.image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array /= 255.

    predictions = model.predict(img_array)
    predicted_class = np.argmax(predictions[0])
    class_labels = list(train_generator.class_indices.keys())
    return class_labels[predicted_class]

# Example prediction
img_path = '/content/drive/MyDrive/dataset/test/some_image.jpg'
predicted_class = predict_image(vgg_model, img_path)
print(f"Predicted Class: {predicted_class}")
```

### Interactive Interface

To make the model more user-friendly, we will create an interactive interface that allows users to upload images and get predictions. We can use libraries like Streamlit or Gradio for this purpose. Here is an example using Streamlit:

#### Steps for Creating an Interactive Interface:
1. **Install Streamlit**: Install Streamlit using pip.
2. **Create a Streamlit App**: Write a Streamlit app to accept image uploads and display predictions.

```python
# Install Streamlit
!pip install streamlit

# Create a Streamlit app
%%writefile app.py
import streamlit as st
import tensorflow as tf
import numpy as np
from PIL import Image

# Load the trained model
model = tf.keras.models.load_model('vgg_model.h5')

# Function to predict and display results for a single image
def predict_image(model, img):
    img = img.resize((150, 150))
    img_array = tf.keras.preprocessing.image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array /= 255.
    predictions = model.predict(img_array)
    predicted_class = np.argmax(predictions[0])
    class_labels = list(train_generator.class_indices.keys())
    return class_labels[predicted_class]

# Streamlit app interface
st.title("Crop Plant Disease Identifier")
uploaded_file = st.file_uploader("Choose an image...", type="jpg")
if uploaded_file is not None:
    image = Image.open(uploaded_file)
    st.image(image, caption='Uploaded Image.', use_column_width=True)
    st.write("")
    st.write("Classifying...")
    label = predict_image(model, image)
    st.write(f"Predicted Class: {label}")

# Run the Streamlit app
!streamlit run app.py
```

### Presentation

Finally, we will prepare a presentation to showcase the project. This can be done using tools like PowerPoint, Google Slides, or even Jupyter Notebooks. The presentation should include:
- An introduction to the problem and the solution.
- Description of the dataset and data preparation steps.
- Explanation of the model selection and training process.
- Results and performance metrics.
- Demonstration of the interactive interface.
- Conclusion and future work.

Here is an outline for the presentation:

#### Outline for Presentation:
1. **Introduction**
    - Problem Statement
    - Objective

2. **Dataset and Data Preparation**
    - Data Sourcing
    - Data Augmentation

3. **Model Selection and Training**
    - Pre-trained Models
    - Transfer Learning
    - Training Process

4. **Results**
    - Performance Metrics
    - Example Predictions

5. **Interactive Interface**
    - Description of the Interface
    - Demonstration

6. **Conclusion and Future Work**
    - Summary of Findings
    - Future Improvements

This markdown file provides a comprehensive guide for the entire project, including exploration, model selection, model training, and demo. Follow these steps to complete the crop-plant-disease-identifier project.
