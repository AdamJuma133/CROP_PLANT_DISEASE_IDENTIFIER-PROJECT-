{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdamJuma133/CROP_PLANT_DISEASE_IDENTIFIER-PROJECT-/blob/main/Crop_Plant_Disease_Identifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Z83tLbEFdix"
      },
      "source": [
        "# Crop Plant Disease Identifier AI Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfxyYV_VIYoR"
      },
      "source": [
        "#1. Project Structure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRzXlRvHF8Pr"
      },
      "source": [
        "This project aims to develop a multiclass crop-plant-disease-identifier using a Convolutional Neural Network (CNN) model implemented in a Google Colab notebook. The dataset contains 13 different types of crops, each with healthy and unhealthy leaf classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l96ey_khFCRG",
        "outputId": "8c27222e-1701-4f7a-b11b-520cc4088fad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aP4R2YOnIuwp"
      },
      "source": [
        "1. Exploration\n",
        "\n",
        "1.1 Design Ideation\n",
        "\n",
        "1.2 Data sourcing from Google Drive\n",
        "\n",
        "1.3 Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-vc8cgxKBkL"
      },
      "source": [
        "\n",
        "2. Model Selection\n",
        "\n",
        "2.1 Provide pre-trained models\n",
        "\n",
        "2.2 Compare performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3IBgumkKaQM"
      },
      "source": [
        "\n",
        "3. Model Training\n",
        "\n",
        "3.1 Data split\n",
        "\n",
        "3.2 Transfer learning\n",
        "\n",
        "3.3bEvaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nUtyQ9Mj2yC"
      },
      "source": [
        "# 3. Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRgTVG4gv02L"
      },
      "source": [
        "Design Ideation\n",
        "\n",
        "\n",
        "The goal of this project is to develop a multiclass crop-plant-disease identifier using a Convolutional Neural Network (CNN) model. The dataset contains 13 different types of crops, each with healthy and unhealthy leaf classes. The project will be implemented in a Google Colab notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHERpWK8wQnZ"
      },
      "source": [
        "Data Sourcing\n",
        "\n",
        "The dataset is stored in Google Drive in a folder named PROJECT_CPDI. Within this folder, there are 13 subfolders, each containing its respective crop dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d233GSFmx3xi"
      },
      "source": [
        "Data Preparation\n",
        "\n",
        "1. Connect to Google Drive:\n",
        "\n",
        "  • Mount Google Drive to access the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hP9wHeuo06bf"
      },
      "source": [
        "2. Organize Dataset:\n",
        "\n",
        "  • Ensure the dataset is properly organized into subfolders for each crop type and their respective healthy and unhealthy leaf classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUK_oDZn2a1N"
      },
      "source": [
        "3. Image Data Generators:\n",
        "\n",
        " •Use ImageDataGenerator from TensorFlow/Keras to preprocess and augment the images for training and validation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRuQE-vX3j04"
      },
      "source": [
        "4. Data Splitting:\n",
        "\n",
        " •Split the data into training and validation sets using an 80-20 split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "F84CQmecNPrS"
      },
      "outputs": [],
      "source": [
        "# Exploration\n",
        "\n",
        "## Import Libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikxiT7d0NYGG",
        "outputId": "bda2a673-d8b6-4b3c-e5ad-2285d11f5bda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "## Connect to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Chj7MtPVNkgY"
      },
      "outputs": [],
      "source": [
        "# Set Dataset Path\n",
        "DATASET_PATH = '/ https://drive.google.com/drive/folders/1T4Ye1kEe93H9BXj-GpOfDoL1DEYXkluu?usp=drive_link '"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKpR9FWwNy1d",
        "outputId": "2063d801-8cf8-4eaa-9a80-712802ed33d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3900 images belonging to 18 classes.\n",
            "Found 967 images belonging to 18 classes.\n"
          ]
        }
      ],
      "source": [
        "# Set Dataset Path\n",
        "DATASET_PATH = '/content/drive/MyDrive/CROP_PLANT_DISEASE_IDENTIFIER(PROJECT CPDI)'  # Assuming your dataset is in a folder named PROJECT_CPDI in your Google Drive\n",
        "\n",
        "# Data Preparation\n",
        "\n",
        "# Image Data Generators\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    DATASET_PATH,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    DATASET_PATH,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "oGrC3f-PFwgx"
      },
      "outputs": [],
      "source": [
        "# Set Dataset Path\n",
        "DATASET_PATH = '/https://drive.google.com/drive/folders/1T4Ye1kEe93H9BXj-GpOfDoL1DEYXkluu ' # Removed extra forward slash from path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hy0qWQY--MNn"
      },
      "source": [
        "# Model Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thCRT3kU-ofD"
      },
      "source": [
        "Compare Performance\n",
        "\n",
        "\n",
        "We will compare the performance of VGG16 and ResNet50 models on the validation set. The comparison will be based on the validation accuracy and loss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGnLW1Gl-Z77"
      },
      "source": [
        "Provide Pre-trained Models\n",
        "\n",
        "\n",
        "We will use pre-trained models VGG16 and ResNet50 for transfer learning. These models are widely used for image classification tasks and have shown good performance on various datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gjIn4n5_hTb",
        "outputId": "60a8400b-994b-44e2-c324-7ba02e338cb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m  9/122\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:54:23\u001b[0m 61s/step - accuracy: 0.2569 - loss: 2.7369"
          ]
        }
      ],
      "source": [
        "# Model Selection\n",
        "\n",
        "## Import Libraries\n",
        "from tensorflow.keras.applications import VGG16, ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "## Load Pre-trained Models\n",
        "vgg16_base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "resnet50_base = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "## Build Models\n",
        "def build_model(base_model):\n",
        "    x = base_model.output\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    return model\n",
        "vgg16_model = build_model(vgg16_base)\n",
        "resnet50_model = build_model(resnet50_base)\n",
        "\n",
        "## Compile Models\n",
        "vgg16_model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "resnet50_model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "## Compare Performance\n",
        "history_vgg16 = vgg16_model.fit(train_generator, validation_data=validation_generator, epochs=10)\n",
        "history_resnet50 = resnet50_model.fit(train_generator, validation_data=validation_generator, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9XgJJXsjHaAm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5490e115-7c59-4406-c987-18535bb70434"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "\n",
        "## Load Pre-trained Models\n",
        "vgg16_base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "resnet50_base = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "id": "14wzLUaNHbYt",
        "outputId": "f23ae72c-db5f-4c87-90a2-27bc2ee7be4f"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'train_generator' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-f85acf830076>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mvgg16_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg16_base\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mresnet50_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet50_base\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-f85acf830076>\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(base_model)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_generator' is not defined"
          ]
        }
      ],
      "source": [
        "## Build Models\n",
        "def build_model(base_model):\n",
        "    x = base_model.output\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    return model\n",
        "vgg16_model = build_model(vgg16_base)\n",
        "resnet50_model = build_model(resnet50_base)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STFdypk8HcSD"
      },
      "outputs": [],
      "source": [
        "##Compile Models\n",
        "vgg16_model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "resnet50_model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIvyjSICHdGB"
      },
      "outputs": [],
      "source": [
        "# Model Selection\n",
        "\n",
        "## Import Libraries\n",
        "from tensorflow.keras.applications import VGG16, ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d7_btAFHd1w"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5QI52gFHemB"
      },
      "outputs": [],
      "source": [
        "## Load Pre-trained Models\n",
        "vgg16_base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "resnet50_base = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cw4aTTH2Il7u"
      },
      "outputs": [],
      "source": [
        "## Build Models\n",
        "def build_model(base_model):\n",
        "    x = base_model.output\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    return model\n",
        "\n",
        "vgg16_model = build_model(vgg16_base)\n",
        "resnet50_model = build_model(resnet50_base)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zrfctawAIZh"
      },
      "source": [
        "# Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 665
        },
        "id": "0_3cbgAOBK8e",
        "outputId": "8024ae7b-412a-4627-b527-26545e2ffd4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'train_generator' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-7aa39281f72c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mvgg16_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg16_base\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mresnet50_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet50_base\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-7aa39281f72c>\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(base_model)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_generator' is not defined"
          ]
        }
      ],
      "source": [
        "# Model Training\n",
        "\n",
        "## Import Libraries\n",
        "from tensorflow.keras.applications import VGG16, ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "## Build Models\n",
        "def build_model(base_model):\n",
        "    x = base_model.output\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    return model\n",
        "\n",
        "vgg16_model = build_model(vgg16_base)\n",
        "resnet50_model = build_model(resnet50_base)\n",
        "\n",
        "## Compile Models\n",
        "vgg16_model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "resnet50_model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "## Train Models\n",
        "history_vgg16 = vgg16_model.fit(train_generator, validation_data=validation_generator, epochs=10)\n",
        "history_resnet50 = resnet50_model.fit(train_generator, validation_data=validation_generator, epochs=10)\n",
        "\n",
        "## Evaluate the Best Model\n",
        "best_model = vgg16_model if max(history_vgg16.history['val_accuracy']) > max(history_resnet50.history['val_accuracy']) else resnet50_model\n",
        "\n",
        "# Evaluate the best model\n",
        "evaluation = best_model.evaluate(validation_generator)\n",
        "\n",
        "print(f\"Validation Loss: {evaluation[0]}\")\n",
        "print(f\"Validation Accuracy: {evaluation[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtloIAMFAOiz"
      },
      "source": [
        "Data Split\n",
        "\n",
        "The data has already been split into training and validation sets using an 80-20 split during the data preparation step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqK3Ali0Afzv"
      },
      "source": [
        "Transfer Learning\n",
        "\n",
        "We use transfer learning with pre-trained models VGG16 and ResNet50. The models are fine-tuned on our dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nAzaKNMAp3G"
      },
      "source": [
        "Evaluation\n",
        "\n",
        "We evaluate the models based on their validation accuracy and loss. The best model is selected for further use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcbG29fqJpLe"
      },
      "outputs": [],
      "source": [
        "## Load Pre-trained Models\n",
        "vgg16_base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "resnet50_base = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}